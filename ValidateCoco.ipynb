{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e362ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Original categories:\n",
      "- id 0: acne\n",
      "- id 1: acne\n",
      "- id 2: dark circle\n",
      "- id 3: wrinkle\n",
      "‚ö†Ô∏è duplicate acne (id 1) ‚Üí remap to 0\n",
      "\n",
      "‚úÖ Saved fixed COCO annotations ‚Üí SkinProblem/train\\_annotations_fixed.coco.json\n",
      "\n",
      "üìå Cleaned categories:\n",
      "- id 0: acne\n",
      "- id 2: dark circle\n",
      "- id 3: wrinkle\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "base_dir = \"SkinProblem/train\"\n",
    "coco_json = os.path.join(base_dir, \"_annotations.coco.json\")\n",
    "\n",
    "if not os.path.exists(coco_json):\n",
    "    raise FileNotFoundError(f\"‚ùå COCO file not found at {coco_json}\")\n",
    "\n",
    "with open(coco_json, \"r\") as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "# check original categories\n",
    "print(\"\\nüìå Original categories:\")\n",
    "for cat in coco[\"categories\"]:\n",
    "    print(f\"- id {cat['id']}: {cat['name']}\")\n",
    "\n",
    "# fix duplicates\n",
    "seen = {}\n",
    "duplicate_map = {}\n",
    "new_categories = []\n",
    "for cat in coco[\"categories\"]:\n",
    "    if cat[\"name\"] in seen:\n",
    "        print(f\"‚ö†Ô∏è duplicate {cat['name']} (id {cat['id']}) ‚Üí remap to {seen[cat['name']]}\")\n",
    "        duplicate_map[cat[\"id\"]] = seen[cat[\"name\"]]\n",
    "    else:\n",
    "        seen[cat[\"name\"]] = cat[\"id\"]\n",
    "        new_categories.append(cat)\n",
    "\n",
    "for ann in coco[\"annotations\"]:\n",
    "    if ann[\"category_id\"] in duplicate_map:\n",
    "        ann[\"category_id\"] = duplicate_map[ann[\"category_id\"]]\n",
    "\n",
    "coco[\"categories\"] = new_categories\n",
    "\n",
    "fixed_path = os.path.join(base_dir, \"_annotations_fixed.coco.json\")\n",
    "with open(fixed_path, \"w\") as f:\n",
    "    json.dump(coco, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved fixed COCO annotations ‚Üí {fixed_path}\")\n",
    "print(\"\\nüìå Cleaned categories:\")\n",
    "for cat in coco[\"categories\"]:\n",
    "    print(f\"- id {cat['id']}: {cat['name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23fdd228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting COCO ‚Üí YOLOv8-seg labels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6513/6513 [00:03<00:00, 1704.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Conversion complete! YOLOv8-seg labels created in train/labels/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "coco_json_path = os.path.join(base_dir, \"_annotations_fixed.coco.json\")\n",
    "lbl_dir = os.path.join(base_dir, \"labels\")\n",
    "os.makedirs(lbl_dir, exist_ok=True)\n",
    "\n",
    "with open(coco_json_path, \"r\") as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "cat2id = {cat[\"id\"]: i for i, cat in enumerate(coco[\"categories\"])}\n",
    "\n",
    "img2anns = {}\n",
    "for ann in coco[\"annotations\"]:\n",
    "    img2anns.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "\n",
    "print(\"\\nConverting COCO ‚Üí YOLOv8-seg labels...\")\n",
    "for img in tqdm(coco[\"images\"]):\n",
    "    img_id = img[\"id\"]\n",
    "    anns = img2anns.get(img_id, [])\n",
    "    label_path = Path(lbl_dir) / (Path(img[\"file_name\"]).stem + \".txt\")\n",
    "\n",
    "    with open(label_path, \"w\") as f:\n",
    "        for ann in anns:\n",
    "            cls_id = cat2id[ann[\"category_id\"]]\n",
    "            h, w = img[\"height\"], img[\"width\"]\n",
    "\n",
    "            if \"segmentation\" in ann and len(ann[\"segmentation\"]) > 0:\n",
    "                seg = ann[\"segmentation\"][0]\n",
    "                norm_seg = [str(seg[i] / w if i % 2 == 0 else seg[i] / h) for i in range(len(seg))]\n",
    "                f.write(f\"{cls_id} \" + \" \".join(norm_seg) + \"\\n\")\n",
    "            else:\n",
    "                x, y, bw, bh = ann[\"bbox\"]\n",
    "                poly = [x, y, x+bw, y, x+bw, y+bh, x, y+bh]\n",
    "                norm_seg = [str(poly[i] / w if i % 2 == 0 else poly[i] / h) for i in range(len(poly))]\n",
    "                f.write(f\"{cls_id} \" + \" \".join(norm_seg) + \"\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ Conversion complete! YOLOv8-seg labels created in train/labels/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7c9cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä YOLO label counts after conversion:\n",
      "- acne: 16497 polygons\n",
      "- dark circle: 3999 polygons\n",
      "- wrinkle: 17885 polygons\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "class_counts = {i: 0 for i in range(len(coco[\"categories\"]))}\n",
    "label_files = glob.glob(os.path.join(lbl_dir, \"*.txt\"))\n",
    "\n",
    "for lf in label_files:\n",
    "    with open(lf) as f:\n",
    "        for line in f:\n",
    "            cls = int(line.strip().split()[0])\n",
    "            class_counts[cls] += 1\n",
    "\n",
    "print(\"\\nüìä YOLO label counts after conversion:\")\n",
    "for cat in coco[\"categories\"]:\n",
    "    print(f\"- {cat['name']}: {class_counts[cat2id[cat['id']]]} polygons\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb26a233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Checking dataset consistency...\n",
      "Classes (3): ['acne', 'dark circle', 'wrinkle']\n",
      "Found 6513 images and 6513 label files\n",
      "‚úÖ All images have corresponding label files.\n",
      "\n",
      "üìä Label counts per class:\n",
      "- acne: 16497 polygons\n",
      "- dark circle: 3999 polygons\n",
      "- wrinkle: 17885 polygons\n",
      "\n",
      "‚úÖ All labels contain valid class IDs.\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "base_dir = \"SkinProblem/train\"\n",
    "img_dir = base_dir  # images are still here\n",
    "lbl_dir = os.path.join(base_dir, \"labels\")\n",
    "\n",
    "# Load categories from fixed COCO file\n",
    "import json\n",
    "coco_json_path = os.path.join(base_dir, \"_annotations_fixed.coco.json\")\n",
    "with open(coco_json_path, \"r\") as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "class_names = [cat[\"name\"] for cat in coco[\"categories\"]]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"\\nüìÇ Checking dataset consistency...\")\n",
    "print(f\"Classes ({num_classes}): {class_names}\")\n",
    "\n",
    "# Collect files\n",
    "image_files = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")))\n",
    "label_files = sorted(glob.glob(os.path.join(lbl_dir, \"*.txt\")))\n",
    "\n",
    "print(f\"Found {len(image_files)} images and {len(label_files)} label files\")\n",
    "\n",
    "# Check if every image has a label file\n",
    "missing_labels = []\n",
    "for img_file in image_files:\n",
    "    lbl_file = os.path.join(lbl_dir, Path(img_file).stem + \".txt\")\n",
    "    if not os.path.exists(lbl_file):\n",
    "        missing_labels.append(img_file)\n",
    "\n",
    "if missing_labels:\n",
    "    print(f\"‚ö†Ô∏è {len(missing_labels)} images have no labels. Example: {missing_labels[:5]}\")\n",
    "else:\n",
    "    print(\"‚úÖ All images have corresponding label files.\")\n",
    "\n",
    "# Check label validity + counts\n",
    "class_counts = {i: 0 for i in range(num_classes)}\n",
    "bad_labels = []\n",
    "\n",
    "for lf in label_files:\n",
    "    with open(lf) as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if not parts:\n",
    "                continue\n",
    "            cls = int(parts[0])\n",
    "            if cls < 0 or cls >= num_classes:\n",
    "                bad_labels.append((lf, line.strip()))\n",
    "            else:\n",
    "                class_counts[cls] += 1\n",
    "\n",
    "print(\"\\nüìä Label counts per class:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"- {name}: {class_counts[i]} polygons\")\n",
    "\n",
    "if bad_labels:\n",
    "    print(f\"\\‚ö†Ô∏è Found {len(bad_labels)} invalid class IDs! Example: {bad_labels[:5]}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All labels contain valid class IDs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43add7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Moved 6513 images into 'train/images/' folder.\n"
     ]
    }
   ],
   "source": [
    "import os, glob, shutil\n",
    "\n",
    "# Base paths\n",
    "base_dir = \"SkinProblem/train\"\n",
    "img_dir = os.path.join(base_dir, \"images\")\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "# Move all image files (jpg/png/jpeg)\n",
    "extensions = [\"*.jpg\", \"*.jpeg\", \"*.png\"]\n",
    "moved_count = 0\n",
    "\n",
    "for ext in extensions:\n",
    "    for img_file in glob.glob(os.path.join(base_dir, ext)):\n",
    "        dst = os.path.join(img_dir, os.path.basename(img_file))\n",
    "        if not os.path.exists(dst):  # avoid overwriting\n",
    "            shutil.move(img_file, dst)\n",
    "            moved_count += 1\n",
    "\n",
    "print(f\"‚úÖ Moved {moved_count} images into 'train/images/' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764fde40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Checking dataset consistency...\n",
      "Found 6513 images and 6513 label files\n",
      "‚úÖ All images have corresponding label files.\n",
      "\n",
      "üìä Label counts per class:\n",
      "- acne: 16497 polygons\n",
      "- dark circle: 3999 polygons\n",
      "- wrinkle: 17885 polygons\n",
      "\n",
      "‚úÖ Label consistency check complete.\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "from collections import Counter\n",
    "\n",
    "# Paths\n",
    "base_dir = \"SkinProblem/train\"\n",
    "img_dir = os.path.join(base_dir, \"images\")\n",
    "lbl_dir = os.path.join(base_dir, \"labels\")\n",
    "\n",
    "# Define classes (must match your training config)\n",
    "classes = [\"acne\", \"dark circle\", \"wrinkle\"]\n",
    "\n",
    "print(\"üìÇ Checking dataset consistency...\")\n",
    "\n",
    "# Collect files\n",
    "images = {os.path.splitext(os.path.basename(f))[0] for f in glob.glob(os.path.join(img_dir, \"*\"))}\n",
    "labels = {os.path.splitext(os.path.basename(f))[0] for f in glob.glob(os.path.join(lbl_dir, \"*.txt\"))}\n",
    "\n",
    "# 1Ô∏è‚É£ Check image-label matching\n",
    "missing_labels = images - labels\n",
    "missing_images = labels - images\n",
    "\n",
    "print(f\"Found {len(images)} images and {len(labels)} label files\")\n",
    "if missing_labels:\n",
    "    print(f\"‚ö†Ô∏è {len(missing_labels)} images without labels (e.g., {list(missing_labels)[:5]})\")\n",
    "if missing_images:\n",
    "    print(f\"‚ö†Ô∏è {len(missing_images)} labels without images (e.g., {list(missing_images)[:5]})\")\n",
    "if not missing_labels and not missing_images:\n",
    "    print(\"‚úÖ All images have corresponding label files.\")\n",
    "\n",
    "# 2Ô∏è‚É£ Validate labels\n",
    "class_counts = Counter()\n",
    "bad_labels = []\n",
    "for lbl_file in glob.glob(os.path.join(lbl_dir, \"*.txt\")):\n",
    "    with open(lbl_file) as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if not parts:\n",
    "                bad_labels.append(lbl_file)\n",
    "                continue\n",
    "            cls = int(parts[0])\n",
    "            if cls < 0 or cls >= len(classes):\n",
    "                print(f\"‚ùå Invalid class ID {cls} in {lbl_file}\")\n",
    "            else:\n",
    "                class_counts[cls] += 1\n",
    "\n",
    "if bad_labels:\n",
    "    print(f\"‚ö†Ô∏è {len(bad_labels)} empty label files found.\")\n",
    "\n",
    "# 3Ô∏è‚É£ Print summary\n",
    "print(\"\\nüìä Label counts per class:\")\n",
    "for i, cname in enumerate(classes):\n",
    "    print(f\"- {cname}: {class_counts[i]} polygons\")\n",
    "\n",
    "print(\"\\n‚úÖ Label consistency check complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
